# Cognitive Core Service - AI Agent Orchestration

> **‚ö†Ô∏è DOCUMENTATION MAINTENANCE REQUIRED**  
> When making changes to this service, you MUST update this README if the changes affect:
> - Agent specifications (input/output schemas, prompts)
> - Event schemas (published/consumed events)
> - Agent orchestration workflows
> - Environment variables or AI model configuration
> - Inter-agent communication protocols

---

## üéØ **Service Overview**

### **Purpose**
The AI brain of the UX-Flow-Engine that orchestrates 9 specialized AI agents to process user requests, create detailed execution plans, and manage intelligent conversation flow using multiple AI providers (Google Gemini, OpenAI, Claude). Acts as the central cognitive hub for all AI-powered interactions with enterprise-grade reliability and multi-provider failover.

### **Core Responsibilities**
- **Multi-Agent Orchestration**: Coordinates 9 specialized AI agents in complex workflows with intelligent task routing
- **Multi-Provider AI Management**: Google Gemini (primary), OpenAI GPT-4 (fallback), Claude 3 (alternative) with automatic failover
- **Conversation Management**: Maintains hierarchical conversation state and context across user sessions (short/mid/long-term memory)
- **Plan Generation & Execution**: Creates detailed execution plans for UX tasks and converts them to executable transactions
- **Response Synthesis**: Combines multiple agent outputs into coherent user responses with context awareness
- **Quality Mode Management**: Handles standard vs pro AI model usage based on task complexity with provider optimization

### **Implementation Status: ‚úÖ 100% PRODUCTION READY**
- **Core Services**: 100% implemented with multi-provider support
- **AI Agent System**: 100% implemented (9 agents with BaseAgent pattern)
- **Orchestration Layer**: 100% implemented (AgentHub, ConversationFlow, StateManager)
- **Testing Suite**: 100% implemented (unit, integration, coverage)
- **Production Infrastructure**: 100% implemented (Docker, Kubernetes, monitoring)
- **Multi-Provider Integration**: 100% implemented (Gemini, OpenAI, Claude)

### **Service Dependencies**

#### **Input Dependencies (Services this service consumes)**
| Service | Communication Method | Purpose | Required |
|---------|---------------------|---------|----------|
| `api-gateway` | Redis Events | Receives user messages and plan approvals | Yes |
| `knowledge-service` | Redis Events | Receives RAG context for informed responses | No |
| `flow-service` | Redis Events | Receives current flow state for plan generation | Yes |

#### **Output Dependencies (Services that consume this service)**
| Service | Communication Method | What they get from us | Critical |
|---------|---------------------|----------------------|----------|
| `api-gateway` | Redis Events | User responses and plan proposals | Yes |
| `knowledge-service` | Redis Events | Knowledge queries for RAG context | No |
| `flow-service` | Redis Events | Flow update transactions | Yes |

#### **External Dependencies**
| Dependency | Type | Purpose | Fallback Strategy |
|------------|------|---------|------------------|
| Google Gemini API | External AI API | Primary AI model inference | Automatic OpenAI/Claude failover |
| OpenAI API | External AI API | Fallback AI model inference | Claude fallback, degraded responses |
| Claude API | External AI API | Alternative AI model inference | Gemini/OpenAI fallback |
| MongoDB Atlas | Database | Conversation persistence | Circuit breaker, memory-only mode |
| Redis | Cache/Events | State management & inter-service communication | Event queuing with retry |

---

## üîå **API Contract Specification**

### **Base URL**
- **Development**: `http://localhost:3001`
- **Production**: `https://api.uxflow.app/cognitive-core`

### **Authentication**
- **Type**: None (internal service)
- **Communication**: Redis event-based with other services

### **API Endpoints**

#### **GET /health**
**Purpose**: Service health check with dependency status and multi-provider health

**Authentication**: ‚ùå Not required

**Response Schema** (200 Success):
```json
{
  "service": "cognitive-core",
  "status": "ok|degraded|error",
  "version": "2.0.0",
  "uptime": 12345,
  "dependencies": {
    "mongodb": "ok|error",
    "redis": "ok|error",
    "ai-providers": {
      "google-gemini": "ok|degraded|error",
      "openai": "ok|degraded|disabled",
      "claude": "ok|degraded|disabled"
    }
  },
  "agents": {
    "available": ["manager", "planner", "architect", "validator", "classifier", "synthesizer", "uxExpert", "visualInterpreter", "analyst"],
    "status": "active",
    "utilization": {
      "manager": { "used": 2, "total": 5 },
      "planner": { "used": 1, "total": 3 }
    }
  },
  "systemMetrics": {
    "activeConversations": 25,
    "queueLength": 3,
    "processingTasks": 8,
    "totalRequests": 15420,
    "successRate": 0.987
  },
  "timestamp": "ISO8601"
}
```

#### **GET /agents**
**Purpose**: List available agents and their detailed status

**Response Schema** (200 Success):
```json
{
  "agents": ["manager", "planner", "architect", "validator", "classifier", "synthesizer", "uxExpert", "visualInterpreter", "analyst"],
  "status": "active",
  "agentDetails": {
    "manager": {
      "capabilities": ["task_coordination", "complexity_assessment"],
      "currentLoad": 2,
      "maxConcurrency": 5,
      "averageResponseTime": 1250,
      "successRate": 0.995
    }
  },
  "workflowPatterns": ["user_message_processing", "plan_execution", "visual_interpretation", "system_analysis"]
}
```

#### **POST /agents/:agentName/invoke**
**Purpose**: Manual agent invocation for testing and debugging

**Request Schema**:
```json
{
  "prompt": "string|object",
  "context": {
    "qualityMode": "standard|pro",
    "currentFlow": "object",
    "ragContext": "string",
    "additionalContext": "object",
    "preferredProvider": "google-gemini|openai|claude"
  }
}
```

**Response Schema** (200 Success):
```json
{
  "success": true,
  "result": "object|string - agent-specific response format",
  "metadata": {
    "provider": "google-gemini",
    "processingTime": 1250,
    "qualityMode": "standard",
    "fallbackUsed": false
  }
}
```

#### **GET /providers**
**Purpose**: Get AI provider status and statistics

**Response Schema** (200 Success):
```json
{
  "primaryProvider": "google-gemini",
  "availableProviders": 3,
  "healthyProviders": 2,
  "providers": {
    "google-gemini": {
      "status": "healthy",
      "requests": 5420,
      "successRate": 0.998,
      "averageResponseTime": 2100
    },
    "openai": {
      "status": "healthy", 
      "requests": 124,
      "successRate": 0.992,
      "averageResponseTime": 1800
    },
    "claude": {
      "status": "disabled",
      "reason": "API key not provided"
    }
  }
}
```

---

## üì° **Event-Driven Communication**

### **Published Events (Events this service emits)**

#### **USER_RESPONSE_READY**
- **Trigger**: After processing user message through agent workflow
- **Frequency**: Per user interaction (variable volume)
- **Consumers**: API Gateway

**Event Schema**:
```json
{
  "eventType": "USER_RESPONSE_READY",
  "eventId": "uuid",
  "timestamp": "ISO8601",
  "emittedBy": "cognitive-core",
  "data": {
    "userId": "string",
    "projectId": "string",
    "response": {
      "type": "plan_for_approval|answer|clarification_needed",
      "message": "string",
      "plan": "array - if type is plan_for_approval",
      "metadata": {
        "complexity": "simple|complex|very_complex",
        "agentsInvolved": ["agent", "names"],
        "question": "string - if clarification needed",
        "aiProvider": "google-gemini|openai|claude",
        "processingTime": 2340,
        "fallbackUsed": false
      }
    },
    "originalEventId": "string"
  },
  "metadata": {
    "correlationId": "string",
    "processingTimeMs": "number"
  }
}
```

#### **KNOWLEDGE_QUERY_REQUESTED**
- **Trigger**: When UX Expert agent needs RAG context
- **Frequency**: Subset of user interactions
- **Consumers**: Knowledge Service

#### **FLOW_UPDATE_REQUESTED**
- **Trigger**: After plan approval and transaction generation
- **Frequency**: Per approved plan
- **Consumers**: Flow Service

#### **AGENT_TASK_STARTED / AGENT_TASK_COMPLETED / AGENT_TASK_FAILED**
- **Trigger**: Agent lifecycle events with enhanced metrics
- **Frequency**: Multiple per user interaction
- **Consumers**: Monitoring, Analytics

#### **CONVERSATION_STATE_CHANGED**
- **Trigger**: When conversation transitions between states
- **Frequency**: Per conversation state change
- **Consumers**: Analytics, Monitoring

#### **AI_PROVIDER_HEALTH_CHANGED**
- **Trigger**: When AI provider health status changes
- **Frequency**: On provider health changes
- **Consumers**: Monitoring, AlertManager

### **Consumed Events (Events this service listens to)**

#### **USER_MESSAGE_RECEIVED**
- **Source**: API Gateway
- **Purpose**: Start AI processing workflow for user conversations
- **Handler**: `src/orchestrator/event-handlers.js:handleUserMessage`
- **Failure Strategy**: Retry 2x with exponential backoff, emit error event

#### **USER_PLAN_APPROVED / USER_PLAN_REJECTED**
- **Source**: API Gateway
- **Purpose**: Handle user plan approval/rejection workflow
- **Handler**: `src/orchestrator/event-handlers.js:handlePlanApproval`
- **Failure Strategy**: Retry 3x, log error, notify user of system issue

---

## üóÑÔ∏è **Data Layer Specification**

### **Database Schema**

#### **Collection: `conversations`**
```json
{
  "_id": "ObjectId",
  "conversationId": "string - userId-projectId",
  "userId": "string",
  "projectId": "string",
  "sessionId": "string",
  "state": "idle|processing|waiting_for_approval|waiting_for_clarification|executing|error",
  "lastMessage": "string",
  "lastResponse": {
    "type": "string",
    "message": "string",
    "metadata": "object"
  },
  "classification": {
    "intent": "string",
    "sentiment": "string",
    "tasks": ["array"],
    "questions": ["array"]
  },
  "context": {
    "shortTerm": ["array - last 5 messages"],
    "midTerm": ["array - episode summaries"],
    "longTerm": {
      "preferences": ["array"],
      "entities": "object",
      "projectContext": "string"
    },
    "knowledgeContext": "string",
    "currentFlow": "object"
  },
  "conversationHistory": [
    {
      "id": "string",
      "role": "user|assistant|system",
      "content": "string",
      "timestamp": "Date",
      "metadata": {
        "aiProvider": "string",
        "processingTime": "number"
      }
    }
  ],
  "agentHistory": [
    {
      "agentName": "string",
      "taskId": "string",
      "input": "object",
      "output": "object",
      "executionTimeMs": "number",
      "timestamp": "Date",
      "aiProvider": "string",
      "success": "boolean"
    }
  ],
  "createdAt": "Date",
  "updatedAt": "Date",
  "lastActivity": "Date"
}
```

#### **Collection: `agent_performance`**
```json
{
  "_id": "ObjectId",
  "agentName": "string",
  "taskId": "string",
  "executionTimeMs": "number",
  "inputTokens": "number",
  "outputTokens": "number",
  "qualityMode": "string",
  "aiProvider": "google-gemini|openai|claude",
  "success": "boolean",
  "errorType": "string",
  "timestamp": "Date"
}
```

#### **Collection: `provider_metrics`**
```json
{
  "_id": "ObjectId",
  "provider": "google-gemini|openai|claude",
  "date": "Date",
  "metrics": {
    "requests": "number",
    "successes": "number",
    "failures": "number",
    "averageResponseTime": "number",
    "totalTokens": "number",
    "errorTypes": "object"
  },
  "createdAt": "Date"
}
```

### **Cache Strategy**

#### **Redis Cache Keys**
| Pattern | TTL | Purpose | Invalidation |
|---------|-----|---------|-------------|
| `conversation:{conversationId}` | 3600s | Conversation state with hierarchical memory | On new message |
| `agent:prompt:{agentName}:{hash}` | 86400s | Prompt template cache | On prompt update |
| `provider:health:{provider}` | 300s | AI provider health status | On health check |
| `model:response:{hash}` | 1800s | AI model response cache | TTL expiry |
| `flow:state:{userId}:{projectId}` | 1800s | Flow state cache | On flow update |
| `system:metrics` | 60s | System performance metrics | On metrics update |

---

## ‚öôÔ∏è **Configuration & Environment**

### **Environment Variables**
| Variable | Required | Default | Description | Example |
|----------|----------|---------|-------------|---------|
| `COGNITIVE_CORE_PORT` | ‚úÖ | `3001` | HTTP server port | `3001` |
| `NODE_ENV` | ‚úÖ | `development` | Environment mode | `production` |
| `LOG_LEVEL` | ‚ùå | `info` | Logging verbosity | `debug` |
| **AI Provider Configuration** |||||
| `GOOGLE_API_KEY` | ‚úÖ | - | Google Gemini API key (primary) | `AIza...` |
| `OPENAI_API_KEY` | ‚ùå | - | OpenAI API key (fallback) | `sk-...` |
| `CLAUDE_API_KEY` | ‚ùå | - | Claude API key (alternative) | `sk-ant-...` |
| **Database Configuration** |||||
| `MONGODB_URI` | ‚úÖ | - | Database connection | `mongodb://...` |
| `REDIS_URL` | ‚úÖ | - | Redis connection | `redis://...` |
| **Agent Configuration** |||||
| `AGENT_DEFAULT_QUALITY_MODE` | ‚ùå | `standard` | Default AI model quality | `pro` |
| `AGENT_RETRY_ATTEMPTS` | ‚ùå | `2` | AI call retry count | `3` |
| `AGENT_TIMEOUT_MS` | ‚ùå | `30000` | AI call timeout | `60000` |
| **Multi-Provider Settings** |||||
| `PRIMARY_AI_PROVIDER` | ‚ùå | `google-gemini` | Primary AI provider | `openai` |
| `ENABLE_AI_FAILOVER` | ‚ùå | `true` | Enable automatic failover | `false` |
| `ENABLE_LOAD_BALANCING` | ‚ùå | `false` | Enable provider load balancing | `true` |
| **Feature Flags** |||||
| `ENABLE_VISION_AGENT` | ‚ùå | `true` | Enable visual interpretation | `false` |
| `ENABLE_CONVERSATION_PERSISTENCE` | ‚ùå | `true` | Store conversation history | `false` |
| `ENABLE_PERFORMANCE_ANALYTICS` | ‚ùå | `false` | Detailed agent metrics | `true` |

### **Secrets (Managed via Secret Manager)**
| Secret Name | Purpose | Rotation | Access Level |
|-------------|---------|----------|--------------|
| `GOOGLE_API_KEY` | Gemini API authentication | Monthly | Service account only |
| `OPENAI_API_KEY` | OpenAI API authentication | Monthly | Service account only |
| `CLAUDE_API_KEY` | Claude API authentication | Monthly | Service account only |
| `MONGODB_CONNECTION_STRING` | Database access | Quarterly | Critical services only |

### **Feature Flags**
| Flag | Default | Purpose | Dependencies |
|------|---------|---------|-------------|
| `ENABLE_MULTI_PROVIDER` | `true` | Enable multi-provider AI system | Multiple API keys |
| `ENABLE_CONVERSATION_MEMORY` | `true` | Enable hierarchical memory system | MongoDB |
| `ENABLE_AGENT_PERFORMANCE_TRACKING` | `true` | Track detailed agent metrics | MongoDB |
| `ENABLE_PROVIDER_HEALTH_MONITORING` | `true` | Monitor AI provider health | Redis |

---

## üõ†Ô∏è **Development & Operations**

### **Local Development Setup**
```bash
# Prerequisites
node --version  # Requires Node.js 18+
npm --version   # Requires npm 8+
docker --version # Requires Docker 20+

# Installation
git clone <repository>
cd services/cognitive-core
npm install

# Environment setup
cp .env.example .env
# Edit .env with your configuration:
# GOOGLE_API_KEY=your_gemini_api_key (required)
# OPENAI_API_KEY=your_openai_key (optional for fallback)
# CLAUDE_API_KEY=your_claude_key (optional for alternative)
# MONGODB_URI=mongodb://localhost:27017/ux-flow-engine
# REDIS_URL=redis://localhost:6379

# Start with Docker Compose (recommended)
docker-compose up --build

# Or start directly
npm run dev

# Verify service health
curl http://localhost:3001/health | jq

# Test agent invocation
curl -X POST http://localhost:3001/agents/classifier/invoke \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Create a login screen", "context": {"qualityMode": "standard"}}'
```

### **Testing**
```bash
# Unit tests (individual agents and components)
npm test

# Unit tests only
npm run test:unit

# Integration tests (agent workflows and orchestration)
npm run test:integration

# Coverage report (80% minimum requirement)
npm run test:coverage

# Watch mode for development
npm run test:watch

# Test specific agent
npm test -- --testPathPattern=manager.test.js

# Test with specific provider
GOOGLE_API_KEY=test npm test

# CI/CD pipeline tests
npm run test:ci
```

### **Build & Deploy**

#### **Docker Development**
```bash
# Build Docker image
docker build -t cognitive-core .

# Run with dependencies (recommended)
docker-compose up --build

# Check logs
docker-compose logs -f cognitive-core

# Access services
curl http://localhost:3001/health     # Cognitive Core
curl http://localhost:8082            # MongoDB Express
curl http://localhost:8081            # Redis Commander
```

#### **Production Deployment**
```bash
# Deploy to Kubernetes
kubectl apply -f k8s/deployment.yaml

# Check deployment status
kubectl get pods -l app=cognitive-core -n ux-flow-engine

# View logs
kubectl logs -l app=cognitive-core -n ux-flow-engine

# Scale deployment
kubectl scale deployment cognitive-core --replicas=5 -n ux-flow-engine

# Check auto-scaling
kubectl get hpa cognitive-core-hpa -n ux-flow-engine
```

---

## üè• **Health & Monitoring**

### **Health Check Endpoints**

#### **GET /health**
Comprehensive service health with all dependencies and AI providers

**Response Time**: < 500ms  
**Dependencies Checked**: 
- MongoDB connection and query capability
- Redis connection and pub/sub functionality  
- Google Gemini API availability and token usage
- OpenAI API health (if configured)
- Claude API health (if configured)
- Agent system health and utilization
- Conversation flow manager status
- System resource utilization

#### **GET /health/detailed**
Extended health information including:
- Detailed agent performance metrics
- AI provider usage statistics
- Conversation statistics
- System performance metrics
- Recent error summaries

### **Metrics & Observability**
- **Metrics Endpoint**: `/metrics` (Prometheus format)
- **Key Performance Indicators**:
  - Agent processing time (p50, p95, p99) per agent type
  - AI provider response times and success rates
  - Multi-provider failover frequency and success
  - Conversation completion rates and user satisfaction
  - Agent success/failure rates by provider
  - Event processing latency and queue lengths
  - Hierarchical memory system performance
  - Token usage and cost optimization across providers

### **Logging Standards**
```json
{
  "timestamp": "ISO8601",
  "level": "info|warn|error|debug",
  "service": "cognitive-core",
  "component": "agent|orchestrator|event-handler|provider-manager",
  "agentName": "string - if agent-related",
  "taskId": "string - if task-related",
  "aiProvider": "google-gemini|openai|claude",
  "message": "Human readable message",
  "correlationId": "string",
  "userId": "string",
  "projectId": "string",
  "metadata": {
    "executionTimeMs": "number",
    "tokenUsage": "object",
    "qualityMode": "string",
    "fallbackUsed": "boolean",
    "providerHealth": "object"
  }
}
```

### **Alert Conditions**
| Metric | Threshold | Severity | Action |
|--------|-----------|----------|--------|
| Agent failure rate | > 5% | High | Check AI provider status, review prompts |
| Primary AI provider failure | > 3 consecutive | Critical | Verify API keys, check provider status |
| All AI providers down | Any failure | Critical | Emergency escalation, check all API keys |
| Conversation processing errors | > 3 consecutive | Critical | Check dependencies, review agent pipeline |
| Memory usage | > 1GB | Medium | Investigate conversation state cleanup |
| Queue length | > 50 tasks | Medium | Check agent capacity, consider scaling |
| Provider failover rate | > 20% | Medium | Investigate primary provider reliability |

---

## üîß **Service-Specific Implementation Details**

### **Enhanced AI Agent Architecture**
The service implements a sophisticated multi-agent system with multi-provider support:

**Core Agents** (Enhanced):
- **Classifier**: Intent recognition with confidence scoring
- **Manager**: Task coordination with complexity assessment and context analysis
- **Planner**: Detailed execution plan creation with RAG integration
- **Architect**: Plan-to-transaction conversion with validation
- **Validator**: Transaction validation with comprehensive error reporting
- **Synthesizer**: Response composition with context awareness

**Specialized Agents** (Enhanced):
- **UX Expert**: Knowledge-based consultation with RAG integration
- **Visual Interpreter**: Image/sketch analysis using vision models across providers
- **Analyst**: System improvement recommendations with performance analytics

### **Multi-Provider AI System**
```
Primary: Google Gemini ‚Üí Fallback: OpenAI GPT-4 ‚Üí Alternative: Claude 3
                ‚Üì
        Intelligent Routing & Load Balancing
                ‚Üì
        Health Monitoring & Auto-Failover
```

**Provider Selection Logic**:
- **Task Requirements**: Vision support, JSON output, context length
- **Provider Health**: Real-time health monitoring and failure tracking
- **Performance Metrics**: Response time, success rate, cost optimization
- **Load Balancing**: Distribute load based on provider capacity

### **Agent Orchestration Workflow** (Enhanced)
```
User Message ‚Üí Classifier ‚Üí Manager ‚Üí [Planner ‚Üí Architect ‚Üí Validator] OR [UX Expert] ‚Üí Synthesizer ‚Üí User Response
                     ‚Üì                                  ‚Üì
              Visual Interpreter (if image)    ConversationFlow (state management)
                     ‚Üì                                  ‚Üì
              Analyst (background)           StateManager (resource management)
                     ‚Üì                                  ‚Üì
              AgentHub (performance tracking)    AIProviderManager (multi-provider)
```

### **Hierarchical Memory System**
- **Short-term Memory**: Last 5 messages with full context
- **Mid-term Memory**: Episode summaries (10-15 message groups)
- **Long-term Memory**: Extracted entities, preferences, and patterns
- **Context Integration**: Intelligent context building for AI prompts

### **Critical Code Paths & Performance**
- **Message Processing**: Classifier ‚Üí Manager ‚Üí Agent Pipeline ‚Üí Synthesizer (95% of traffic)
- **Plan Execution**: Plan Approval ‚Üí Architect ‚Üí Validator ‚Üí Flow Update (high business value)
- **Error Recovery**: Multi-provider failover ‚Üí Fallback responses ‚Üí User notification (critical UX)
- **Performance Targets**: < 2s standard, < 5s pro, 99.9% uptime with multi-provider

### **Enhanced Security Considerations**
- AI prompt injection prevention through input sanitization
- Multi-provider API key rotation and secure storage
- Conversation data encryption at rest and in transit
- User context isolation between projects and workspaces
- Rate limiting and abuse prevention across all AI providers
- GDPR compliance for conversation data and analytics

---

## üö® **Troubleshooting Guide**

### **Common Issues**

#### **Service Won't Start**
```bash
# Check environment variables
node -e "console.log(process.env.GOOGLE_API_KEY ? 'Gemini: OK' : 'Gemini: Missing')"

# Test database connections
npm run test:db

# Check all provider health
curl http://localhost:3001/providers

# Verify Docker setup
docker-compose ps
```

#### **AI Provider Issues**
```bash
# Check provider health
curl http://localhost:3001/providers | jq

# Test primary provider
curl -X POST http://localhost:3001/agents/classifier/invoke \
  -H "Content-Type: application/json" \
  -d '{"prompt": "test", "context": {"preferredProvider": "google-gemini"}}'

# Check failover mechanism
# (Temporarily disable primary provider to test)
curl http://localhost:3001/health | jq .dependencies.ai-providers

# Review provider metrics
docker logs cognitive-core | grep -E "(provider|failover)"
```

#### **Agent Performance Issues**
```bash
# Check agent utilization
curl http://localhost:3001/agents | jq .agentDetails

# Monitor agent performance
curl http://localhost:3001/metrics | grep agent_

# Test specific agent
curl -X POST http://localhost:3001/agents/manager/invoke \
  -H "Content-Type: application/json" \
  -d '{"prompt": "test task", "context": {"qualityMode": "standard"}}'

# Check conversation state
redis-cli GET "conversation:userId-projectId"
```

#### **Memory & Resource Issues**
```bash
# Check system resources
curl http://localhost:3001/health | jq .systemMetrics

# Monitor memory usage
docker stats cognitive-core

# Check conversation cleanup
mongosh $MONGODB_URI --eval "db.conversations.count()"

# Review task queue
curl http://localhost:3001/health | jq .systemMetrics.queueLength
```

### **Debug Mode**
```bash
# Enable comprehensive debugging
LOG_LEVEL=debug npm run dev

# Enable specific component debugging
DEBUG=agent:*,provider:*,conversation:* npm run dev

# Test with verbose logging
npm run test -- --verbose

# Monitor provider health
docker-compose logs -f cognitive-core | grep "provider\|health"
```

---

## üìö **Additional Resources**

### **Related Documentation**
- [System Architecture Overview](../../docs/ARCHITECTURE.md)
- [AI Agent Design Patterns](../../docs/AI_AGENTS.md)
- [Multi-Provider Integration Guide](../../docs/AI_PROVIDERS.md)
- [Conversation Memory System](../../docs/MEMORY_SYSTEM.md)
- [Event System Documentation](../../docs/EVENTS.md)
- [Flow Transaction Specification](../flow-service/TRANSACTIONS.md)

### **External References**
- [Google Gemini API Documentation](https://ai.google.dev/docs)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Claude API Documentation](https://docs.anthropic.com/claude/reference)
- [Node.js Express.js Framework](https://expressjs.com/en/guide/)
- [Redis Pub/Sub Documentation](https://redis.io/docs/manual/pubsub/)

---

## üìù **Changelog**

### **Version 2.0.0** (2024-02-01) - ‚úÖ PRODUCTION READY
- **‚úÖ Complete production implementation** with multi-provider AI system
- **‚úÖ Enhanced multi-agent orchestration** with AgentHub, ConversationFlow, StateManager
- **‚úÖ Multi-provider failover system** (Gemini ‚Üí OpenAI ‚Üí Claude) with intelligent routing
- **‚úÖ Hierarchical conversation memory** with short/mid/long-term context management
- **‚úÖ Comprehensive testing suite** (unit, integration, coverage 80%+)
- **‚úÖ Production-ready infrastructure** (Docker, Kubernetes, auto-scaling, monitoring)
- **‚úÖ Enhanced error handling** with graceful degradation and multi-provider fallback
- **‚úÖ Performance optimizations** for high-throughput scenarios with resource management

### **Version 1.1.0** (2024-01-15) - Previous Implementation
- Added Visual Interpreter agent for image analysis
- Improved error handling and retry mechanisms
- Performance optimizations for high-throughput scenarios
- Enhanced logging and monitoring capabilities

### **Version 1.0.0** (2024-01-15) - Initial Implementation
- Initial multi-agent system implementation
- Core 9 agents with Google Gemini integration
- Event-driven communication with other services
- Conversation state management

---

## üë• **Maintainers**

| Role | Contact | Responsibilities |
|------|---------|-----------------|
| Service Owner | @ai-team-lead | Agent architecture, AI integration decisions, multi-provider strategy |
| Primary Developer | @cognitive-dev | Agent implementation, prompt engineering, orchestration systems |
| AI Integration Specialist | @ai-integration-dev | Multi-provider management, failover systems, performance optimization |
| DevOps Contact | @platform-team | Deployment, monitoring, scaling, Kubernetes management |
| QA Lead | @qa-team | Test strategy, quality assurance, performance testing |

---

> **üîÑ Last Updated**: 2024-02-01  
> **üìã Documentation Version**: 2.0  
> **ü§ñ Implementation Status**: ‚úÖ 100% PRODUCTION READY  
> **üîß Auto-validation**: ‚úÖ Agent schemas validated / ‚úÖ Event schemas current / ‚úÖ API contracts tested / ‚úÖ Multi-provider tested / ‚úÖ Performance benchmarked