Skizze des Wissensmanagements: Das Gehirn unserer KI
Unser System basiert auf einer fundamentalen PrÃ¤misse: Ein brillanter Assistent benÃ¶tigt zwei Arten von GedÃ¤chtnis:

Konversations-GedÃ¤chtnis: Er muss sich daran erinnern, was besprochen wurde.

Projekt-Wissen: Er muss verstehen, was der aktuelle Stand des Projekts ist.

Diese beiden SÃ¤ulen werden von zwei dedizierten Services verwaltet: der ContextEngine und dem KnowledgeAggregator.

ğŸ›ï¸ SÃ¤ule 1: Die ContextEngine (Das Konversations-GedÃ¤chtnis)
Zweck: Dieser Service ist der "Archivar" unserer Dialoge. Seine einzige Aufgabe ist es, den (potenziell sehr langen) Chat-Verlauf aus der MongoDB zu lesen und ihn in ein fÃ¼r die KI verstÃ¤ndliches, mehrschichtiges GedÃ¤chtnis aufzubereiten.

Das mehrschichtige GedÃ¤chtnismodell
Wir fassen den Chat nicht einfach nur zusammen, da dabei kritische Details verloren gehen kÃ¶nnten. Stattdessen strukturieren wir ihn in drei Ebenen:

ğŸ§  KurzzeitgedÃ¤chtnis (Sliding Window):

Was es ist: Die letzten 4-6 Nachrichten des Dialogs.

Wie es funktioniert: Diese Nachrichten werden immer wortwÃ¶rtlich und unverÃ¤ndert bereitgestellt.

Nutzen: Verhindert das "Dementia"-Problem. Der Assistent weiÃŸ immer exakt, was er gerade gesagt hat und was du geantwortet hast. Dies ist entscheidend fÃ¼r natÃ¼rliche RÃ¼ckfragen und kontextbezogene Antworten.

ğŸ“– MittelzeitgedÃ¤chtnis (Episodische Zusammenfassungen):

Was es ist: Eine Art "Inhaltsverzeichnis" der bisherigen Konversation.

Wie es funktioniert: Alle 10-15 Nachrichten wird der Summarizer-Agent aufgerufen, um diesen abgeschlossenen Block zu einem "Kapitel" zusammenzufassen (z.B., "Kapitel 1: Der Nutzer hat die Erstellung eines Login-Flows beauftragt und die Implementierung von SSO explizit abgelehnt.").

Nutzen: Gibt der KI einen schnellen Ãœberblick Ã¼ber die wichtigsten Phasen und Entscheidungen der Vergangenheit, ohne den gesamten Verlauf lesen zu mÃ¼ssen. Das hilft, den Fokus zu behalten.

ğŸ’¾ LangzeitgedÃ¤chtnis (Strukturierte Fakten):

Was es ist: Die absolute, maschinenlesbare Wahrheit des Projekts.

Wie es funktioniert: Nach jeder "Episode" analysiert der KnowledgeExtractor-Agent den Dialog und extrahiert die harten Fakten (z.B. "SSO_implementierung: false") und EntitÃ¤ten (z.B. {"n_123": "Login Screen"}) in ein strukturiertes JSON-Objekt.

Nutzen: Hier gehen keine Details verloren. Diese Fakten kÃ¶nnen direkt an Agenten wie den Architekten weitergegeben werden, um absolute Konsistenz zu gewÃ¤hrleisten.

ğŸ“š SÃ¤ule 2: Der KnowledgeAggregator (Das Projekt-Wissen via RAG)
Zweck: Dieser Service ist der "Bibliothekar". Er macht das Wissen, das auÃŸerhalb der Konversation liegt â€“ also deine eigentlichen Projektdateien und globales Fachwissen â€“ fÃ¼r die KI durchsuchbar. Er nutzt dafÃ¼r eine ChromaDB Vektor-Datenbank.

Das mehrschichtige RAG-Modell
Um Datensicherheit und Relevanz zu garantieren, ist das Wissen in drei klar getrennten Ebenen organisiert:

ğŸŒ Ebene 1: Globales Wissen:

Was es ist: Von uns definierte "FachbÃ¼cher" wie UX-Heuristiken, Barrierefreiheits-Richtlinien und die .uxflow-Spezifikation.

FÃ¼r wen: FÃ¼r alle Nutzer des Systems verfÃ¼gbar.

Nutzen: Stellt sicher, dass die KI immer auf einer Grundlage von bewÃ¤hrten Best Practices agiert.

ğŸ¢ Ebene 2: Workspace-Wissen:

Was es ist: Alle .uxflow-Dateien, wiederverwendbare Komponenten, Personas und Design-System-Regeln, die zu einem spezifischen Team/Workspace gehÃ¶ren.

FÃ¼r wen: Nur fÃ¼r Mitglieder des jeweiligen Workspaces sichtbar (gefiltert Ã¼ber workspaceId).

Nutzen: Garantiert Team-Konsistenz und ermÃ¶glicht es der KI, VorschlÃ¤ge zu machen, die zum Stil des jeweiligen Projekts passen.

ğŸ‘¤ Ebene 3: Nutzer-Wissen:

Was es ist: Gelernte, persÃ¶nliche Vorlieben und Interaktionsmuster eines einzelnen Nutzers.

FÃ¼r wen: Nur fÃ¼r den jeweiligen Nutzer sichtbar (gefiltert Ã¼ber userId).

Nutzen: ErmÃ¶glicht eine tiefgehende Personalisierung. Das System passt sich an deinen individuellen Arbeitsstil an.



Zusammengefasst:

Der Manager-Agent ist der Einzige, der das volle Konversations-GedÃ¤chtnis (ContextEngine) erhÃ¤lt, um den Dialog zu verstehen und strategische Entscheidungen zu treffen.

Die Spezialisten (Planner, UX-Expert etc.) erhalten gezielte Wissens-Ausschnitte aus dem Projekt-Wissen, die exakt auf ihre aktuelle Aufgabe zugeschnitten sind.
Diese Trennung stellt sicher, dass unser System sowohl extrem kontextbewusst als auch hocheffizient arbeitet.